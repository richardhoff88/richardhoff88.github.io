---
title: "Home"
layout: splash
permalink: /
---

<style>
article.splash .page__content {
  font-size: 1.1rem;
  line-height: 1.6;
}

article.splash .page__content h1,
article.splash .page__content h2 {
  font-size: 1.2rem;
}
</style>

<img src="website.JPG" alt="Richard Hoffmann" 
     style="float: right; padding: 30px; max-width: 30%; min-width: 270px; width: 50%; height: auto; border-radius: 50px;" />



<!-- ![Richard Hoffmann](website.JPG)
{:style="float: right; padding: 30px; max-width: 30%; min-width: 270px;"} -->

<br/>
Hey! I'm Richard, a second-year undergrad at [Caltech](https://www.caltech.edu/) studying Computer Science and minoring in Mathematics and Control & Dynamical Systems (CDS). 

My interest is in building scalable models for solving hard problems. I'm particularly interested in applications to self-driving vehicles and intelligent robotics, specifically through spatial reasoning, large language models, model predictive control, and perception/vision.

Currently, I'm improving VLM reasoning and spatial awareness in [Glab](https://gkioxari.github.io/). I'm also working on LLM pre and post-training to prove Olympiad-level (and beyond) inequalities under [Prof. Tony Yue Yu](https://tyy.caltech.edu/) at [Caltech](https://pma.caltech.edu/). I've previously worked under [Dr. Alec Reed](https://www.colorado.edu/cs/alec-reed) at CU Boulder's [Autonomous Robotics Lab](https://arpg.github.io/) on predictive vehicle dynamics.

Last summer, I worked on software development and operations research at [Commerzbank](https://www.commerzbank.de/group/) in New York City. I'm in Seattle this summer interning at [Amazon](https://aws.amazon.com/?nc2=h_lg)!

If you'd like to chat, please reach out at rhoffman@caltech.edu.

## Recent News
last updated: June 2025

- Adversarial attacks on stochastic bandits often rely on unrealistic assumptions like unrestricted, per-round reward manipulation. We introduce a more practical threat model, Fake Data Injection, where the attacker injects a limited number of bounded fake feedback samples. We demonstrate both theoretically and empirically that [Practical Adversarial Attacks on Stochastic Bandits via Fake Data Injection
](https://arxiv.org/abs/2505.21938) can effectively mislead popular algorithms like UCB and Thompson Sampling with minimal attack cost.

- We explore a novel neural population code method to accurately estimate object orientation. I'm excited to see how [Object-Pose Estimation With Neural Population Codes](https://arxiv.org/abs/2502.13403) can be scaled to enhance robot perception and improve autonomous vehicle driving. 